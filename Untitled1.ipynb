{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,time,csv,random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read complete\n"
     ]
    }
   ],
   "source": [
    "fp=open('training.1600000.processed.noemoticon.csv','r')\n",
    "reader=csv.reader(fp)\n",
    "data=[]\n",
    "for line in reader:\n",
    "\ttemp_data=line[len(line)-1]\n",
    "\tlabel=int(line[0])\n",
    "\twords=temp_data.split()\n",
    "\tfor i in range(0,len(words)):\n",
    "\t\tif(\"http\" in words[i]):\n",
    "\t\t\twords[i]=''\n",
    "\t\telse:\n",
    "\t\t\twords[i]=words[i].lower()\n",
    "\ttemp_data=' '.join(words)\n",
    "\tdata.append((temp_data,label))\n",
    "\t\n",
    "print('read complete')\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle complete\n"
     ]
    }
   ],
   "source": [
    "data=data[:4000]\n",
    "print('shuffle complete')\n",
    "L=len(data)\n",
    "train_data=[i[0] for i in data[:int(0.8*L)]]\n",
    "train_labels=[i[1] for i in data[:int(0.8*L)]]\n",
    "test_data=[i[0] for i in data[int(0.8*L):]]\n",
    "test_labels=[i[1] for i in data[int(0.8*L):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((train_data, test_data), axis=0)\n",
    "y = np.concatenate((train_labels, test_labels), axis=0)\n",
    "\n",
    "vocabulory=np.unique(np.hstack(X))\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "for i in train_data:\n",
    "\tX_train.append(text.one_hot(i,len(vocabulory)))\n",
    "for i in test_data:\n",
    "\tX_test.append(text.one_hot(i,len(vocabulory)))\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=300)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF complete\n"
     ]
    }
   ],
   "source": [
    "tf=TfidfVectorizer(min_df=5,max_df = 0.8,sublinear_tf=True,use_idf=True,decode_error='ignore')\n",
    "# cv=CountVectorizer()\n",
    "\n",
    "\n",
    "train_tf_vectors=tf.fit_transform(train_data)\n",
    "test_tf_vectors=tf.transform(test_data)\n",
    "\n",
    "print('TF-IDF complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training completed\n",
      "TF-IDF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.72      0.73       425\n",
      "          4       0.69      0.70      0.69       375\n",
      "\n",
      "avg / total       0.71      0.71      0.71       800\n",
      "\n",
      "0.71125\n"
     ]
    }
   ],
   "source": [
    "classifier_lin = svm.SVC(kernel='linear')\n",
    "classifier_lin.fit(train_tf_vectors,train_labels)\n",
    "print(\"training completed\")\n",
    "prediction_rbf=classifier_lin.predict(test_tf_vectors)\n",
    "print(\"TF-IDF\")\n",
    "print(classification_report(test_labels, prediction_rbf))\n",
    "print(accuracy_score(test_labels, prediction_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0################\n"
     ]
    }
   ],
   "source": [
    "print(\"2.0################\")\n",
    "classifier_lin = svm.SVC(kernel='linear')\n",
    "classifier_lin.fit(X_train,train_labels)\n",
    "print(\"training completed\")\n",
    "prediction_rbf=classifier_lin.predict(X_test)\n",
    "print(\"TF-IDF\")\n",
    "print(classification_report(test_labels, prediction_rbf))\n",
    "print(accuracy_score(test_labels, prediction_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
